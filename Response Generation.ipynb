{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-23T09:51:05.360066Z","iopub.status.busy":"2024-06-23T09:51:05.359094Z","iopub.status.idle":"2024-06-23T09:51:05.365415Z","shell.execute_reply":"2024-06-23T09:51:05.364343Z","shell.execute_reply.started":"2024-06-23T09:51:05.360023Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","from IPython.display import clear_output\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:37:16.476813Z","iopub.status.busy":"2024-06-23T09:37:16.475908Z","iopub.status.idle":"2024-06-23T09:37:16.813652Z","shell.execute_reply":"2024-06-23T09:37:16.812524Z","shell.execute_reply.started":"2024-06-23T09:37:16.476781Z"},"trusted":true},"outputs":[],"source":["# Load the data\n","df = pd.read_csv('Customer-Support.csv')\n","\n","# Split the data into train and test sets\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Initialize the BART tokenizer\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:37:53.376003Z","iopub.status.busy":"2024-06-23T09:37:53.375558Z","iopub.status.idle":"2024-06-23T09:37:53.390518Z","shell.execute_reply":"2024-06-23T09:37:53.389499Z","shell.execute_reply.started":"2024-06-23T09:37:53.375956Z"},"trusted":true},"outputs":[],"source":["\n","# Custom dataset class for customer support data\n","class CustomerSupportDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=128):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        query = self.data.iloc[idx]['query']\n","        response = self.data.iloc[idx]['response']\n","        # Tokenize the input query\n","        inputs = self.tokenizer.encode_plus(\n","            query,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        # Tokenize the target response\n","        targets = self.tokenizer.encode_plus(\n","            response,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'labels': targets['input_ids'].flatten()\n","        }\n","\n","# Create dataset objects\n","train_dataset = CustomerSupportDataset(train_df, tokenizer)\n","test_dataset = CustomerSupportDataset(test_df, tokenizer)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:38:21.853773Z","iopub.status.busy":"2024-06-23T09:38:21.853413Z","iopub.status.idle":"2024-06-23T09:38:23.316715Z","shell.execute_reply":"2024-06-23T09:38:23.315796Z","shell.execute_reply.started":"2024-06-23T09:38:21.853744Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartDecoderLayer(\n","          (self_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize the model\n","model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","\n","# Set up the device (GPU if available, else CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:39:23.265511Z","iopub.status.busy":"2024-06-23T09:39:23.264814Z","iopub.status.idle":"2024-06-23T09:39:31.531765Z","shell.execute_reply":"2024-06-23T09:39:31.530667Z","shell.execute_reply.started":"2024-06-23T09:39:23.265475Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 8/8 [00:01<00:00,  4.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Average Loss: 12.1531\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 8/8 [00:01<00:00,  5.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/5, Average Loss: 10.2478\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 8/8 [00:01<00:00,  5.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/5, Average Loss: 9.2034\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 8/8 [00:01<00:00,  5.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/5, Average Loss: 7.6451\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 8/8 [00:01<00:00,  5.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/5, Average Loss: 5.6795\n"]}],"source":["\n","# Set up the data loader for training\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","# Set up the optimizer\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","# Training loop\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n","        # Move batch to device\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","        # Zero out any existing gradients\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        # Backward pass\n","        loss.backward()\n","        # Update model parameters\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    \n","    # Print average loss for the epoch\n","    avg_loss = total_loss / len(train_loader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n","\n","# Save the model\n","torch.save(model.state_dict(), 'customer_support_bart_model.pth')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:40:10.797192Z","iopub.status.busy":"2024-06-23T09:40:10.796784Z","iopub.status.idle":"2024-06-23T09:40:10.929463Z","shell.execute_reply":"2024-06-23T09:40:10.928705Z","shell.execute_reply.started":"2024-06-23T09:40:10.797162Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 2/2 [00:00<00:00, 16.57it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Loss: 4.1536\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Evaluation loop\n","model.eval()\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n","\n","total_loss = 0\n","\n","with torch.no_grad():\n","    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","avg_loss = total_loss / len(test_loader)\n","print(f\"Test Loss: {avg_loss:.4f}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:40:43.518836Z","iopub.status.busy":"2024-06-23T09:40:43.517923Z","iopub.status.idle":"2024-06-23T09:40:43.525519Z","shell.execute_reply":"2024-06-23T09:40:43.524487Z","shell.execute_reply.started":"2024-06-23T09:40:43.518803Z"},"trusted":true},"outputs":[],"source":["# Function to generate responses\n","def generate_response(query, model, tokenizer, max_length=128):\n","    model.eval()\n","    \n","    inputs = tokenizer.encode_plus(\n","        query,\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","\n","    input_ids = inputs['input_ids'].to(device)\n","    attention_mask = inputs['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            max_length=max_length,\n","            num_beams=5,\n","            early_stopping=True\n","        )\n","\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:41:57.117657Z","iopub.status.busy":"2024-06-23T09:41:57.116593Z","iopub.status.idle":"2024-06-23T09:41:57.319976Z","shell.execute_reply":"2024-06-23T09:41:57.318910Z","shell.execute_reply.started":"2024-06-23T09:41:57.117620Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Query: Where is my order?\n","Generated Response: We'd be happy to help. Can you please provide your order number?\n"]}],"source":["# Demo\n","query = \"Where is my order?\"\n","response = generate_response(query, model, tokenizer)\n","print(f\"Query: {query}\")\n","print(f\"Generated Response: {response}\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-23T09:47:52.142544Z","iopub.status.busy":"2024-06-23T09:47:52.141805Z","iopub.status.idle":"2024-06-23T09:48:16.819871Z","shell.execute_reply":"2024-06-23T09:48:16.818908Z","shell.execute_reply.started":"2024-06-23T09:47:52.142508Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to the Customer Support Bot!\n","Type your questions and press Enter to get a response.\n","Press 'q' and Enter to quit the demo.\n","\n","==================================================\n","\n"]},{"name":"stdout","output_type":"stream","text":["Your question (or 'q' to quit):  How long does shipping take?\n"]},{"name":"stdout","output_type":"stream","text":["\n","Bot: We'd be happy to help. Can you please provide your shipping address?\n","\n","==================================================\n","\n"]},{"name":"stdout","output_type":"stream","text":["Your question (or 'q' to quit):  q\n"]},{"name":"stdout","output_type":"stream","text":["\n","Thank you for using the Customer Support Bot. Goodbye!\n"]}],"source":["# Demo function\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","model.load_state_dict(torch.load('customer_support_bart_model.pth', map_location=device))\n","model.to(device)\n","model.eval()\n","\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","def generate_response(query, max_length=128):\n","    inputs = tokenizer.encode_plus(\n","        query,\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","\n","    input_ids = inputs['input_ids'].to(device)\n","    attention_mask = inputs['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            max_length=max_length,\n","            num_beams=5,\n","            early_stopping=True\n","        )\n","\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","def run_demo():\n","    print(\"Welcome to the Customer Support Bot!\")\n","    print(\"Type your questions and press Enter to get a response.\")\n","    print(\"Press 'q' and Enter to quit the demo.\")\n","    print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","    while True:\n","        query = input(\"Your question (or 'q' to quit): \")\n","        \n","        if query.lower() == 'q':\n","            print(\"\\nThank you for using the Customer Support Bot. Goodbye!\")\n","            break\n","        \n","        if query:\n","            response = generate_response(query)\n","            print(f\"\\nBot: {response}\\n\")\n","        else:\n","            print(\"\\nPlease enter a question.\\n\")\n","        \n","        print(\"=\"*50 + \"\\n\")\n","\n","# Run the demo\n","run_demo()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5255802,"sourceId":8750541,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
